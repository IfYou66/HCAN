{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tsai.all import *\n",
    "import sklearn.metrics as skm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ],
   "id": "beccd3b9f920a0b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(r\"D:\\a_zyc_file\\a-zouyuechao\\graduation_thesis\\experiment\\time_series_damage_detection\\dataset\\MVS_P2_NM_Z\\train_valid.csv\",header=None)   \n",
    "# df = pd.read_csv(r\"D:\\a_zyc_file\\a-zouyuechao\\graduation_thesis\\experiment\\time_series_damage_detection\\dataset\\sweden\\dataset-train.csv\",header=None)"
   ],
   "id": "db4c6d62d7e3e807"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 以下得到的y没有作用，将被覆盖\n",
    "X, y = df2xy(df, data_cols=None)\n",
    "\n",
    "X=X.reshape(1280,512,40)\n",
    "# X=X.reshape(5120,128,40)\n",
    "# X=X.reshape(528,1000,21)\n",
    "# X=X.reshape(1056,500,21)\n",
    "\n",
    "X=np.transpose(X,(0,2,1))"
   ],
   "id": "795a0ef4311143e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "label = [0] * 64\n",
    "for i in range(64, 512, 64):\n",
    "    print(i)\n",
    "    for j in range(64):\n",
    "        label.append(label[i-1] + 1)\n",
    "for j in range(128):\n",
    "    label.append(8)\n",
    "y = pd.DataFrame(label)\n",
    "\n",
    "# 生成初始序列\n",
    "# label = [0] * 352+[1]*352+[2]*352\n",
    "# y = pd.DataFrame(label)"
   ],
   "id": "3748aa79e2709d56"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "splits = get_splits(y,n_splits=1,valid_size = 0.25,test_size = 0,train_only=False,show_plot=True,check_splits=True,stratify=True, random_state=23, shuffle=True)",
   "id": "46a7d6e0fe5fd71e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# MLSTM_FCNPlus FCNPlus RNN_FCNPlus\n",
    "tfms = [None, TSClassification()]\n",
    "batch_tfms = TSStandardize(by_sample=True)\n",
    "model = TSClassifier(X, y.values, splits=splits, path='models', arch=\"FCNPlus\", tfms=tfms, batch_tfms=batch_tfms, metrics=accuracy, cbs=ShowGraph())\n",
    "import time\n",
    "# 记录训练开始时间\n",
    "start_time = time.time()\n",
    "model.fit_one_cycle(25, 0.001)\n",
    "# 记录训练结束时间\n",
    "end_time = time.time()\n",
    "# 计算并打印训练时间\n",
    "execution_time = end_time - start_time\n",
    "print(f\"训练时间：{execution_time} 秒\")\n",
    "model.export(\"stage1.pkl\")"
   ],
   "id": "ba6c5f255d9dabb6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df2 = pd.read_csv(r\"D:\\a_zyc_file\\a-zouyuechao\\graduation_thesis\\experiment\\time_series_damage_detection\\dataset\\MVS_P2_NM_Z\\test.csv\",header=None)   \n",
    "# df2 = pd.read_csv(r\"D:\\a_zyc_file\\a-zouyuechao\\graduation_thesis\\experiment\\time_series_damage_detection\\dataset\\sweden\\dataset-test.csv\",header=None)\n",
    "\n",
    "X2, y2 = df2xy(df2, data_cols=None)\n",
    "# X2=X2.reshape(1280,128,40)\n",
    "# X2=X2.reshape(264,500,21)\n",
    "X2=X2.reshape(160,1024,40)\n",
    "X2=np.transpose(X2,(0,2,1))\n",
    "\n",
    "label = [0] * 16\n",
    "for i in range(16, 128, 16):\n",
    "    for j in range(16):\n",
    "        label.append(label[i-1] + 1)\n",
    "for j in range(32):\n",
    "    label.append(8)\n",
    "y2 = pd.DataFrame(label)\n",
    "# label2 = [0] * 88+[1]*88+[2]*88\n",
    "# y2 = pd.DataFrame(label2)"
   ],
   "id": "8894e2a46deac2f7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tsai.inference import load_learner\n",
    "\n",
    "mv_clf = load_learner(r'D:\\spyderFile\\models\\stage1.pkl')\n",
    "# 记录推理开始时间\n",
    "start_time1 = time.time()\n",
    "probas, target, preds = model.get_X_preds(X2[:160], y2.values[:160])\n",
    "# 记录推理结束时间\n",
    "end_time1 = time.time()\n",
    "# 计算并打印推理时间\n",
    "execution_time1 = end_time1 - start_time1\n",
    "print(f\"推理时间：{execution_time1} 秒\")"
   ],
   "id": "331cc0479dca4221"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f'accuracy: {skm.accuracy_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int)):10.6f}')\n",
    "print(f'precision: {skm.precision_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int), average=\"weighted\"):10.6f}')\n",
    "print(f'recall: {skm.recall_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int), average=\"weighted\"):10.6f}')\n",
    "print(f'f1: {skm.f1_score(target.to(\"cpu\").numpy().astype(int), preds.astype(int), average=\"weighted\"):10.6f}')"
   ],
   "id": "db34331944ee64f3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "\n",
    "# 假设 model 是你的模型实例\n",
    "# 序列化模型\n",
    "with open(r'C:\\Users\\zero\\models\\stage1.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# 计算文件大小\n",
    "import os\n",
    "file_size = os.path.getsize(r'C:\\Users\\zero\\models\\stage1.pkl')\n",
    "file_size_mb = file_size / (1024 * 1024)\n",
    "print(f\"模型文件大小：{file_size_mb} MB\")\n",
    "\n",
    "# 计算参数数量\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "params_count = count_parameters(model)\n",
    "print(f\"模型参数数量：{params_count // 1000}K\")\n"
   ],
   "id": "b605a5faeeeaf00"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 展示实际损伤分类和预测分类结果\n",
    "model.show_results()"
   ],
   "id": "5e7705705a34e751"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# interp = ClassificationInterpretation.from_learner(model)\n",
    "# interp.plot_confusion_matrix()\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "cm = confusion_matrix(target.to(\"cpu\").numpy().astype(int), preds.astype(int))\n",
    "\n",
    "# 选择颜色方案\n",
    "cmap = 'Blues'  # 或者 'Greys', 'binary'\n",
    "\n",
    "# 使用 seaborn 绘制混淆矩阵\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=cmap,\n",
    "            annot_kws={\"size\": 12})  # 设置注释文本的字体大小\n",
    "\n",
    "# plt.title('Confusion Matrix', fontsize=20)  # 设置标题字体大小\n",
    "# plt.ylabel('True Label', fontsize=16)  # 设置y轴标签字体大小\n",
    "# plt.xlabel('Predicted Label', fontsize=16)  # 设置x轴标签字体大小\n",
    "\n",
    "# 增大刻度标签字体大小\n",
    "plt.tick_params(axis='both', which='major', labelsize=14)\n",
    "\n",
    "# 显示颜色条（可选）\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ],
   "id": "ba7b24f6dc708d0d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.feature_importance(save_df_path=r\"D:\\a_zyc_file\\a-zouyuechao\\graduation_thesis\\experiment\\time_series_damage_detection\\result\\hell.csv\")",
   "id": "f6d7c8f400bace4a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.show_probas()",
   "id": "ecfaccd43ecf659e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tfms  = [None, TSRegression()]\n",
    "dsets = TSDatasets(X, y, tfms=tfms, splits=splits, inplace=True)\n",
    "dls = TSDataLoaders.from_dsets(dsets.train, dsets.valid, bs=[64, 128], batch_tfms=[TSStandardize()], num_workers=0)\n",
    "dls.show_batch(sharey=True)"
   ],
   "id": "167ada246b7b4f19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "nvars = 40\n",
    "seq_len = 1024\n",
    "c_out = 1\n",
    "c_in=40\n",
    "model=MRNN_FCNPlus(c_in, c_out, seq_len)\n",
    "# model= ConvTranPlus(c_in, c_out, seq_len)\n",
    "# model = MLP(nvars, c_out, seq_len)\n",
    "learn = Learner(dls, model, metrics=accuracy)\n",
    "learn.save('stage0')\n",
    "learn.load('stage0')\n",
    "learn.lr_find()\n",
    "learn.fit_one_cycle(100, lr_max=0.001)\n",
    "learn.save('stage1')\n",
    "learn.recorder.plot_metrics()\n",
    "learn.show_results()\n",
    "learn.show_probas()"
   ],
   "id": "d86778c93175fa84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ],
   "id": "4ed5751920617d22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始CSV文件\n",
    "input_file = 'D:\\jupyteNotebookFile\\gjemnessund\\gjemnessund.csv'  # 替换为你的输入文件路径\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# 选择第一列和后6列\n",
    "# 假设CSV文件有n列，那么后6列的索引范围是 n-6 到 n-1\n",
    "first_column = df.iloc[:, 0]  # 第一列\n",
    "last_six_columns = df.iloc[:, -1:]  # 后6列\n",
    "\n",
    "# 将第一列和后6列合并成一个新的DataFrame\n",
    "new_df = pd.concat([first_column, last_six_columns], axis=1)\n",
    "\n",
    "# 保存新的CSV文件\n",
    "output_file = 'D:\\jupyteNotebookFile\\gjemnessund\\gjemnessund_Univariate.csv'  # 替换为你想要保存的新文件路径\n",
    "new_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"新文件已保存到 {output_file}\")"
   ],
   "id": "e9e4f6b8651b7fd3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文字体和负号显示\n",
    "plt.rcParams['font.family'] = ['Microsoft YaHei']  # 选择一个更美观的中文字体\n",
    "plt.rcParams['font.size'] = 12  # 设置全局字体大小\n",
    "plt.rcParams['axes.unicode_minus'] = False  # 用来正常显示负号\n",
    "\n",
    "# 数据：训练时间（秒），MAE误差，存储量（MB）和模型名称\n",
    "train_times = [6.22, 22.48, 28.83, 7.42, 5.50, 12.14, 6.30]  # 训练时间\n",
    "mae_errors = [0.340, 0.926, 1.081, 0.591, 0.693, 0.620, 0.301]  # MAE误差\n",
    "memory = [612, 1415, 414, 533, 1906, 1296, 449]  # 存储量，单位MB\n",
    "models = ['iTransformer', 'Informer', 'Reformer', 'ModernTCN', 'TIDE', 'FreTS', 'RPTM']  # 模型名称\n",
    "\n",
    "# 定义更鲜艳明亮的颜色方案\n",
    "colors = [\n",
    "    [0.2, 0.4, 0.9, 0.9],  # 明亮蓝色\n",
    "    [0.4, 0.9, 0.4, 0.9],  # 明亮绿色\n",
    "    [0.9, 0.4, 0.4, 0.9],  # 明亮红色\n",
    "    [0.6, 0.6, 0.9, 0.9],  # 明亮紫色\n",
    "    [0.9, 0.6, 0.6, 0.9],  # 明亮橙色\n",
    "    [0.6, 0.9, 0.6, 0.9],  # 明亮青色\n",
    "    [0.9, 0.9, 0.6, 0.9]   # 明亮黄色\n",
    "]\n",
    "alpha_value = 0.7  # 透明度值\n",
    "\n",
    "# 绘制散点图，点的大小与存储量成正比，并使用不同的颜色和透明度\n",
    "for i, model in enumerate(models):\n",
    "    plt.scatter([train_times[i]], [mae_errors[i]], s=memory[i]*2, color=colors[i], alpha=alpha_value)\n",
    "\n",
    "# 在每个点旁边标记模型的名称、存储量和训练时间\n",
    "# for i, model in enumerate(models):\n",
    "#     annotation = f\"{model}\\n（{train_times[i]:.2f}s,{memory[i]:.0f}MB）\"\n",
    "#     plt.annotate(annotation, (train_times[i], mae_errors[i]), textcoords=\"offset points\", xytext=(0,0), ha='center', va='center')\n",
    "\n",
    "# 添加网格线\n",
    "plt.grid(True)\n",
    "\n",
    "\n",
    "# 设置图表标题和坐标轴标签\n",
    "plt.title('效率比较', fontsize=14)  # 调整标题字体大小\n",
    "plt.xlabel('训练时间（s/epoch）', fontsize=12)  # 调整x轴标签字体大小\n",
    "plt.ylabel('均方误差', fontsize=12)  # 调整y轴标签字体大小\n"
   ],
   "id": "c5243e2fe42754ba"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
